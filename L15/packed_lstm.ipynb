{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrei-radulescu-banu/stat453-deep-learning-ss21/blob/main/L15/packed_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch==1.13.0 torchtext==0.14.0 torchdata==0.5.0\n",
        "\n",
        "# Reload environment\n",
        "exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quCeAViQxtFC",
        "outputId": "48787628-2873-47fe-98eb-1b5997e30d7b"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchtext==0.14.0 in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Collecting torchdata==0.5.0\n",
            "  Downloading torchdata-0.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 17.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (1.21.6)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 60.9 MB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 80.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (2022.9.24)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.6.0 torchdata-0.5.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kiY4tZXm7Gz"
      },
      "source": [
        "Derived from:\n",
        "STAT 453: Deep Learning (Spring 2021)  \n",
        "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
        "Lecture 15: Introduction to recurrent neural networks\n",
        "\n",
        "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n",
        "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21  \n",
        "Andrei's fork: https://github.com/andrei-radulescu-banu/stat453-deep-learning-ss21\n",
        "\n",
        "Ported by Andrei R-B to torchtext 0.14.0, using new DataPipes.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install watermark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxYMCgA_nBvP",
        "outputId": "a2bff4ab-3fc8-45cf-d930-90d0268cbef4"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting watermark\n",
            "  Downloading watermark-2.3.1-py2.py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from watermark) (7.9.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.2.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 13.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (5.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->watermark) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->watermark) (0.7.0)\n",
            "Installing collected packages: jedi, watermark\n",
            "Successfully installed jedi-0.18.2 watermark-2.3.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4SK0xKAJgm"
      },
      "source": [
        "# RNN Classifier with LSTM Trained on Own Dataset (IMDB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc6xejhY-NzZ"
      },
      "source": [
        "Example notebook showing how to use an own CSV text dataset for training a simple RNN for sentiment classification (here: a binary classification problem with two labels, positive and negative) using LSTM (Long Short Term Memory) cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "moNmVfuvnImW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7fe2ac37-066d-468d-981c-625af7968ff9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Author: Sebastian Raschka, Andrei R-B\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.8.16\n",
            "IPython version      : 7.9.0\n",
            "\n",
            "torch    : 1.13.0+cu116\n",
            "torchtext: 0.14.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark -a 'Sebastian Raschka, Andrei R-B' -v -p torch,torchtext\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSRL42Qgy8I8"
      },
      "source": [
        "## General Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "OvW1RgfepCBq"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "VOCABULARY_SIZE = 20000\n",
        "LEARNING_RATE = 0.005\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 15\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQMmKUEisW4W"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHwOuk54m7G6"
      },
      "source": [
        "The following cells will download the IMDB movie review dataset (http://ai.stanford.edu/~amaas/data/sentiment/) for positive-negative sentiment classification in as CSV-formatted file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "7Kq0XWHom7G6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "380d9512-a159-40ef-f6ca-3d1804136d78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-10 23:15:37--  https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.113.4\n",
            "Connecting to github.com (github.com)|140.82.113.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz [following]\n",
            "--2022-12-10 23:15:37--  https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26521894 (25M) [application/octet-stream]\n",
            "Saving to: ‘movie_data.csv.gz’\n",
            "\n",
            "movie_data.csv.gz   100%[===================>]  25.29M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2022-12-10 23:15:37 (221 MB/s) - ‘movie_data.csv.gz’ saved [26521894/26521894]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hXwZGkBQm7G7"
      },
      "outputs": [],
      "source": [
        "!gunzip -f movie_data.csv.gz "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGreVqRDm7G7"
      },
      "source": [
        "Check that the dataset looks okay:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uVr6xN53m7G8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 548
        },
        "outputId": "dfd5d27a-dfda-4f70-b48d-8e4aae22dc16"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  I recently bought the DVD, forgetting just how...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55a2d92a-d74f-4741-867c-0dfb611807d4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55a2d92a-d74f-4741-867c-0dfb611807d4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55a2d92a-d74f-4741-867c-0dfb611807d4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55a2d92a-d74f-4741-867c-0dfb611807d4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "df = pd.read_csv('movie_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "TCYKMce_m7G9"
      },
      "source": [
        "df.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']\n",
        "df.to_csv('movie_data.csv', index=None)\n",
        "\n",
        "df = pd.read_csv('movie_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ayCZ1etlm7G9"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJJJ1LtSm7G9"
      },
      "source": [
        "## Prepare Dataset with Torchdata and the new DataPipes API"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchdata.datapipes.iter import IterableWrapper, FileOpener\n",
        "datapipe = IterableWrapper([\"movie_data.csv\"])\n",
        "datapipe = FileOpener(datapipe, mode='b')\n",
        "datapipe = datapipe.parse_csv(skip_lines=1)\n",
        "\n",
        "for sample in datapipe:\n",
        "     print(sample)\n",
        "     break"
      ],
      "metadata": {
        "id": "A7Ue2q-1kwIj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47ce505a-0fa5-4de5-c449-dff22dc9a559"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available', '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset into Train/Validation/Test"
      ],
      "metadata": {
        "id": "uuDLF9BA4fuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into training, validation, and test partitions:"
      ],
      "metadata": {
        "id": "FxH6EdtA5CU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows in dataset\n",
        "N_ROWS = len(list(datapipe))  # 50000\n",
        "\n",
        "# Split into training and val datapipes early on. Will build vocabulary from training datapipe only.\n",
        "train_dp, valid_dp, test_dp = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"valid\": 0.1, \"test\": 0.1}, seed=0)\n",
        "\n",
        "print(f'Num Train: {len(train_dp)}')\n",
        "print(f'Num Validate: {len(valid_dp)}')\n",
        "print(f'Num Test: {len(test_dp)}')"
      ],
      "metadata": {
        "id": "We2S_UwOsroc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988c2669-0bd0-43b0-d7f2-c564c50603fb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Train: 40000\n",
            "Num Validate: 5000\n",
            "Num Test: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Vocabulary"
      ],
      "metadata": {
        "id": "RDIpnTf14KmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the vocabulary based on the top `VOCABULARY_SIZE` words. **build_vocab_from_iterator()** collects the most frequent tokens from the iterator **yield_tokens(train_datapipe)**, and adds special tokens at the begginning w/o changing the order of supplied tokens.\n"
      ],
      "metadata": {
        "id": "jRCjbUQK5q1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# See tutorial at https://www.youtube.com/watch?v=CrS-LFXEiyk\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text, _ in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "def get_vocab(train_datapipe):\n",
        "    vocab = build_vocab_from_iterator(yield_tokens(train_datapipe), specials=[\"<UNK>\", \"<PAD>\"], max_tokens=VOCABULARY_SIZE)\n",
        "    vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "aPC6DfASsZrl"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the vocabulary**"
      ],
      "metadata": {
        "id": "wDgg4ub_9zgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = get_vocab(train_dp)\n",
        "print(\"Vocabulary size: \", len(vocab))"
      ],
      "metadata": {
        "id": "PeyMOsYiUhGO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef540735-aaf6-4873-c8a0-0c2606771297"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size:  20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokens corresponding to the first 10 indices (0, 1, ..., 9):**"
      ],
      "metadata": {
        "id": "_3N2yVlx78fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab.get_itos()[:10]) # itos = integer-to-string"
      ],
      "metadata": {
        "id": "RbguzRrs7781",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90e7eabe-08a0-4b75-8635-c8841d32c413"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<UNK>', '<PAD>', 'the', '.', ',', 'and', 'a', 'of', 'to', \"'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch RNNs can deal with arbitrary lengths due to dynamic graphs, but padding is necessary for padding sequences to the same length in a given minibatch so we can store those in an array."
      ],
      "metadata": {
        "id": "3J1xW7i46Luz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting a string to an integer:**"
      ],
      "metadata": {
        "id": "FQusdyKM9df0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A direct way\n",
        "print(f\"the: {vocab['the']}\")\n",
        "\n",
        "# And an indirect way, using get_stoi() to get a dictionary of tokens and values\n",
        "print(f\"the: {vocab.get_stoi()['the']}\") # stoi = string-to-integer\n",
        "\n",
        "# What is the padding value?\n",
        "print(f\"<PAD>: {vocab['<PAD>']}\")\n",
        "PADDING_VALUE=vocab['<PAD>']"
      ],
      "metadata": {
        "id": "2Ipkzrhr770W",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7acdba75-1307-431a-b10b-2208d4d3b4b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the: 2\n",
            "the: 2\n",
            "<PAD>: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How are unknown tokens handled?**"
      ],
      "metadata": {
        "id": "UyeWI9Ci-evW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Default index: {vocab.get_default_index()}\")\n",
        "\n",
        "# Value of unknown token is default index when referenced with [] brackets:\n",
        "vocab['123aaa']"
      ],
      "metadata": {
        "id": "Nl_nM0r3699R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e7739cc9-7c42-4c17-f3c9-dd3946dbcea6"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default index: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both `text_transform` and `label_transform` are the callable object, such as a lambda func here, to process the raw text and label data from the dataset iterators."
      ],
      "metadata": {
        "id": "6bk05mhx_xUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "label_transform = lambda x: 1 if x == '1' else 0\n",
        "\n",
        "# Print out the output of text_transform\n",
        "print(\"input to the text_transform:\", \"here is an example\")\n",
        "print(\"output of the text_transform:\", text_transform(\"here is an example\"))"
      ],
      "metadata": {
        "id": "BLTO10Ha_ygS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "738b408c-11a2-48f3-8714-38891e9970b8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to the text_transform: here is an example\n",
            "output of the text_transform: [135, 10, 41, 476]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How do I convert an array of integers to the corresponding tokens?**"
      ],
      "metadata": {
        "id": "aMrQ41cEKszo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_itos = vocab.get_itos()\n",
        "vec_vocab_itos = np.vectorize(lambda x: vocab_itos[x])\n",
        "vec_vocab_itos([1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "id": "XIBt3bdlKr1t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8f33d5-ec18-460e-8f6a-233c3ca83b67"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<PAD>', 'the', '.', ',', 'and'], dtype='<U5')"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Data Loaders"
      ],
      "metadata": {
        "id": "5ohB-Ern-AmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.utils.data.DataLoader` is used to generate data batch. Users could customize the data batch by defining a function with the `collate_fn` argument in the DataLoader. Here, in the `collate_batch` func, we process the raw text data and add padding to dynamically match the longest sentence in a batch."
      ],
      "metadata": {
        "id": "PnyQAEm4_D9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "def collate_batch(batch):\n",
        "   text_list, label_list = [], []\n",
        "   for (_text, _label) in batch:\n",
        "        label_list.append(label_transform(_label))\n",
        "        processed_text = torch.tensor(text_transform(_text))\n",
        "        text_list.append(processed_text)\n",
        "   return pad_sequence(text_list, padding_value=PADDING_VALUE).to(DEVICE), torch.tensor(label_list).to(DEVICE)"
      ],
      "metadata": {
        "id": "uFAZeWDa_H1g"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To group the texts with similar length together, like introduced in the legacy `BucketIterator` class, first of all, we randomly create multiple \"pools\", and each of them has a size of `batch_size * 100`. Then, we sort the samples within the individual pool by length. This idea can be implemented succintly through `batch_sampler` argument of PyTorch `Dataloader`. `batch_sampler` accepts 'Sampler' or Iterable object that yields indices of next batch. In the code below, we implemented a generator that yields batch of indices for which the corresponding batch of data is of similar length. "
      ],
      "metadata": {
        "id": "PPVGxmEsCR6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = list(train_dp)\n",
        "\n",
        "def batch_sampler():\n",
        "    indices = [(i, len(tokenizer(s[0]))) for i, s in enumerate(train_list)]\n",
        "    random.shuffle(indices)\n",
        "    pooled_indices = []\n",
        "    # create pool of indices with similar lengths \n",
        "    for i in range(0, len(indices), BATCH_SIZE * 100): \n",
        "       pooled_indices.extend(sorted(indices[i:i + BATCH_SIZE * 100], key=lambda x: x[0]))\n",
        "\n",
        "    pooled_indices = [x[1] for x in pooled_indices]\n",
        "\n",
        "    # yield indices for current batch\n",
        "    for i in range(0, len(pooled_indices), BATCH_SIZE):\n",
        "        yield pooled_indices[i:i + BATCH_SIZE]"
      ],
      "metadata": {
        "id": "eH4w2xp3CcA_"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, s in enumerate(train_list):\n",
        "  print(i, s[0])\n",
        "  break"
      ],
      "metadata": {
        "id": "bLwVI49xU4h-",
        "outputId": "9aa77dc4-d6a5-4359-9bc7-108e7995baeb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 OK... so... I really like Kris Kristofferson and his usual easy going delivery of lines in his movies. Age has helped him with his soft spoken low energy style and he will steal a scene effortlessly. But, Disappearance is his misstep. Holy Moly, this was a bad movie! <br /><br />I must give kudos to the cinematography and and the actors, including Kris, for trying their darndest to make sense from this goofy, confusing story! None of it made sense and Kris probably didn't understand it either and he was just going through the motions hoping someone would come up to him and tell him what it was all about! <br /><br />I don't care that everyone on this movie was doing out of love for the project, or some such nonsense... I've seen low budget movies that had a plot for goodness sake! This had none, zilcho, nada, zippo, empty of reason... a complete waste of good talent, scenery and celluloid! <br /><br />I rented this piece of garbage for a buck, and I want my money back! I want my 2 hours back I invested on this Grade F waste of my time! Don't watch this movie, or waste 1 minute of your valuable time while passing through a room where it's playing or even open up the case that is holding the DVD! Believe me, you'll thank me for the advice!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Sampler, DistributedSampler, Dataset\n",
        "\n",
        "# Create our own sampler, to ensure we function with multiple worker threads\n",
        "# See https://discuss.pytorch.org/t/using-distributedsampler-in-combination-with-batch-sampler-to-make-sure-batches-have-sentences-of-similar-length/119824/3\n",
        "class BatchSamplerSimilarLength(Sampler):\n",
        "    def __init__(self, dataset, batch_size, indices=None, shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        # get the indices and length\n",
        "        self.indices = [(i, len(tokenizer(s[0]))) for i, s in enumerate(dataset)]\n",
        "        # if indices are passed, then use only the ones passed (for ddp)\n",
        "        if indices is not None:\n",
        "            self.indices = torch.tensor(self.indices)[indices].tolist()\n",
        "\n",
        "    def __iter__(self):\n",
        "        if self.shuffle:\n",
        "            random.shuffle(self.indices)\n",
        "\n",
        "        pooled_indices = []\n",
        "        # create pool of indices with similar lengths\n",
        "        for i in range(0, len(self.indices), self.batch_size * 100):\n",
        "            pooled_indices.extend(sorted(self.indices[i:i + self.batch_size * 100], key=lambda x: x[0]))\n",
        "        self.pooled_indices = [x[1] for x in pooled_indices]\n",
        "\n",
        "        # yield indices for current batch\n",
        "        batches = [self.pooled_indices[i:i + self.batch_size] for i in\n",
        "                   range(0, len(self.pooled_indices), self.batch_size)]\n",
        "\n",
        "        if self.shuffle:\n",
        "            random.shuffle(batches)\n",
        "        for batch in batches:\n",
        "            yield batch\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pooled_indices) // self.batch_size\n",
        "\n",
        "class DistributedBatchSamplerSimilarLength(DistributedSampler):\n",
        "    def __init__(self, dataset: Dataset, num_replicas = None,\n",
        "                 rank = None, shuffle: bool = True,\n",
        "                 seed: int = 0, drop_last: bool = False, batch_size = 10) -> None:\n",
        "        super().__init__(dataset=dataset, num_replicas=num_replicas, rank=rank, shuffle=shuffle, seed=seed,\n",
        "                         drop_last=drop_last)\n",
        "        self.batch_size = batch_size\n",
        "\n",
        "    def __iter__(self):\n",
        "        indices = list(super().__iter__())\n",
        "        batch_sampler = BatchSamplerSimilarLength(self.dataset, batch_size=self.batch_size, indices=indices)\n",
        "        return iter(batch_sampler)\n",
        "\n",
        "    def __len__(self) -> int:\n",
        "        return self.num_samples//batch_size"
      ],
      "metadata": {
        "id": "vDAmd8BzUD1B"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dp_list = list(train_dp)\n",
        "valid_dp_list = list(valid_dp)\n",
        "test_dp_list = list(test_dp)\n",
        "\n",
        "train_loader = DataLoader(train_dp_list, \n",
        "                          batch_sampler=BatchSamplerSimilarLength(dataset = train_dp_list, \n",
        "                                                                  batch_size=BATCH_SIZE),\n",
        "                          collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(train_dp_list, \n",
        "                          batch_sampler=BatchSamplerSimilarLength(dataset = valid_dp_list, \n",
        "                                                                  batch_size=BATCH_SIZE),\n",
        "                          collate_fn=collate_batch)\n",
        "test_loader = DataLoader(train_dp_list, \n",
        "                          batch_sampler=BatchSamplerSimilarLength(dataset = test_dp_list, \n",
        "                                                                  batch_size=BATCH_SIZE),\n",
        "                          collate_fn=collate_batch)\n",
        "\n",
        "text_batch, label_batch = next(iter(train_loader))\n",
        "print(text_batch.size())\n",
        "print(label_batch.size())"
      ],
      "metadata": {
        "id": "Kzmg30JnXODr",
        "outputId": "86b0252b-56f3-4d6e-af3f-06f63adcaaa1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1247, 128])\n",
            "torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#train_loader = DataLoader(list(train_dp), batch_sampler=batch_sampler(),\n",
        "#                          collate_fn=collate_batch)\n",
        "#valid_loader = DataLoader(list(valid_dp), batch_sampler=batch_sampler(), \n",
        "#                          collate_fn=collate_batch)\n",
        "#test_loader = DataLoader(list(test_dp), batch_sampler=batch_sampler(),\n",
        "#                         collate_fn=collate_batch)\n",
        "\n",
        "\n",
        "#text_batch, label_batch = next(iter(train_loader))\n",
        "#print(text_batch.size())\n",
        "#print(label_batch.size())"
      ],
      "metadata": {
        "id": "izH5UueztrRb"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the iterators (note that the number of rows depends on the longest document in the respective batch):"
      ],
      "metadata": {
        "id": "alhb-l3CSvO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train')\n",
        "for text_batch, label_batch in train_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nValid:')\n",
        "for text_batch, label_batch in valid_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nTest:')\n",
        "for text_batch, label_batch in test_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break"
      ],
      "metadata": {
        "id": "4P65G4zqS1qk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3eab1d76-ac3d-473f-d7b9-924f23074cb1"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "Text matrix size: torch.Size([1153, 128])\n",
            "Target vector size: torch.Size([128])\n",
            "\n",
            "Valid:\n",
            "Text matrix size: torch.Size([1153, 128])\n",
            "Target vector size: torch.Size([128])\n",
            "\n",
            "Test:\n",
            "Text matrix size: torch.Size([999, 128])\n",
            "Target vector size: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In automatic batch mode, `len(train_loader)` is well defined. We're batching manually, and `len(train_loader)` is not defined. "
      ],
      "metadata": {
        "id": "Z5bUjDsrzmbx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The text batch as indices of tokens**"
      ],
      "metadata": {
        "id": "5BcP4qmAOSGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_batch)"
      ],
      "metadata": {
        "id": "oPee-HP-MusQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6f84f40-c6fa-4a45-d5da-72a732221865"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   13,    14,   812,  ...,    27,   943, 11868],\n",
            "        [   57,    21,     8,  ...,     2,     0,    10],\n",
            "        [    9,   526,     2,  ...,   407,    12,     6],\n",
            "        ...,\n",
            "        [    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    1,     1,     1,  ...,     1,     1,     1],\n",
            "        [    1,     1,     1,  ...,     1,     1,     1]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The corresponding vocabulary tokens**\n",
        "\n",
        "Notice how the reviews appear on the tensor columns. Each column has one review."
      ],
      "metadata": {
        "id": "epUvW9z5OYgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec_vocab_itos(text_batch.to(\"cpu\")))"
      ],
      "metadata": {
        "id": "siH213KBMx2O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ee8ff75-4416-4e01-eaa0-715f25a78286"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['i' 'this' 'straight' ... 'on' 'mark' 'saboteur']\n",
            " ['can' 'movie' 'to' ... 'the' '<UNK>' 'is']\n",
            " [\"'\" 'starts' 'the' ... 'face' 'in' 'a']\n",
            " ...\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**And the batch labels**\n",
        "\n",
        "Each element is the review score for the corresponding column."
      ],
      "metadata": {
        "id": "0Pjzqxv1OeBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_batch)"
      ],
      "metadata": {
        "id": "J5NR0SlxN1Qh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "758ddff1-9eb2-4d05-e2c3-70570b3de8ba"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1,\n",
            "        1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1,\n",
            "        1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1,\n",
            "        1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0,\n",
            "        0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0,\n",
            "        0, 1, 1, 0, 1, 1, 1, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The next batch will have different text column size.**\n",
        "\n",
        "The column size is determined by the max length of reviews in a batch. Each batch has a different text column size."
      ],
      "metadata": {
        "id": "SbKYBRznQgi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch, label_batch = next(iter(train_loader))\n",
        "print(f'Text matrix size: {text_batch.size()}')\n",
        "print(f'Target vector size: {label_batch.size()}')\n",
        "\n",
        "text_batch, label_batch = next(iter(train_loader))\n",
        "print(f'Text matrix size: {text_batch.size()}')\n",
        "print(f'Target vector size: {label_batch.size()}')"
      ],
      "metadata": {
        "id": "RFpzgfY5Qfnv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb938881-e499-4ddd-823d-5a325e7bfb9f"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text matrix size: torch.Size([1153, 128])\n",
            "Target vector size: torch.Size([128])\n",
            "Text matrix size: torch.Size([1153, 128])\n",
            "Target vector size: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec_vocab_itos(text_batch.to(\"cpu\")))"
      ],
      "metadata": {
        "id": "BopSzNUXRIOO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "291ccce2-4804-4b00-dfc5-5edd6e3298c4"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['hilarious' 'i' 'lackawanna' ... 'don' 'now' 'ten']\n",
            " ['and' 'must' 'blues' ... \"'\" 'please' 'out']\n",
            " ['low-budget' 'say' \"'\" ... 't' 'don' 'of']\n",
            " ...\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_batch)"
      ],
      "metadata": {
        "id": "yDM8DBXkRJjy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae35dd2c-d677-48a2-ae96-6477ed681466"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0,\n",
            "        0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0,\n",
            "        1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
            "        0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1,\n",
            "        1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1,\n",
            "        0, 1, 0, 0, 0, 0, 0, 1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "YDm8DtLzKR79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute model accuracy on a dataloader**\n",
        "\n",
        "Pass the train, valid or test dataloader\n"
      ],
      "metadata": {
        "id": "wfFF6KruLaZ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "T5t1Afn4xO11"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.float().to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum().to(\"cpu\")\n",
        "\n",
        "    return float(correct_pred)/num_examples * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train a model**\n",
        "\n",
        "This is model- and dataloader-independent."
      ],
      "metadata": {
        "id": "5a24JY8bLmX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, num_epochs, train_loader,\n",
        "                valid_loader, test_loader, optimizer,\n",
        "                device, logging_interval=50,\n",
        "                scheduler=None,\n",
        "                scheduler_on='valid_acc'):\n",
        "\n",
        "    start_time = time.time()\n",
        "    minibatch_loss_list, train_acc_list, valid_acc_list = [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # ## FORWARD AND BACK PROP\n",
        "            logits = model(features)\n",
        "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # ## UPDATE MODEL PARAMETERS\n",
        "            optimizer.step()\n",
        "\n",
        "            # ## LOGGING\n",
        "            minibatch_loss_list.append(loss.item())\n",
        "            if not batch_idx % logging_interval:\n",
        "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                      f'| Batch {batch_idx:04d} '\n",
        "                      f'| Loss: {loss:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():  # save memory during inference\n",
        "            train_acc = compute_accuracy(model, train_loader, device=device)\n",
        "            valid_acc = compute_accuracy(model, valid_loader, device=device)\n",
        "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                  f'| Train: {train_acc :.2f}% '\n",
        "                  f'| Validation: {valid_acc :.2f}%')\n",
        "            train_acc_list.append(train_acc)\n",
        "            valid_acc_list.append(valid_acc)\n",
        "\n",
        "        elapsed = (time.time() - start_time)/60\n",
        "        print(f'Time elapsed: {elapsed:.2f} min')\n",
        "        \n",
        "        if scheduler is not None:\n",
        "\n",
        "            if scheduler_on == 'valid_acc':\n",
        "                scheduler.step(valid_acc_list[-1])\n",
        "            elif scheduler_on == 'minibatch_loss':\n",
        "                scheduler.step(minibatch_loss_list[-1])\n",
        "            else:\n",
        "                raise ValueError(f'Invalid `scheduler_on` choice.')\n",
        "        \n",
        "\n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Total Training Time: {elapsed:.2f} min')\n",
        "\n",
        "    test_acc = compute_accuracy(model, test_loader, device=device)\n",
        "    print(f'Test accuracy {test_acc :.2f}%')\n",
        "\n",
        "    return minibatch_loss_list, train_acc_list, valid_acc_list\n"
      ],
      "metadata": {
        "id": "RYnX6OzjLAYD"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot training loss and accuracy**"
      ],
      "metadata": {
        "id": "DhFkZG_3Lxyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_loss(minibatch_loss_list, num_epochs, iter_per_epoch,\n",
        "                       results_dir=None, averaging_iterations=100):\n",
        "\n",
        "    plt.figure()\n",
        "    ax1 = plt.subplot(1, 1, 1)\n",
        "    ax1.plot(range(len(minibatch_loss_list)),\n",
        "             (minibatch_loss_list), label='Minibatch Loss')\n",
        "\n",
        "    if len(minibatch_loss_list) > 1000:\n",
        "        ax1.set_ylim([\n",
        "            0, np.max(minibatch_loss_list[1000:])*1.5\n",
        "            ])\n",
        "    ax1.set_xlabel('Iterations')\n",
        "    ax1.set_ylabel('Loss')\n",
        "\n",
        "    ax1.plot(np.convolve(minibatch_loss_list,\n",
        "                         np.ones(averaging_iterations,)/averaging_iterations,\n",
        "                         mode='valid'),\n",
        "             label='Running Average')\n",
        "    ax1.legend()\n",
        "\n",
        "    ###################\n",
        "    # Set scond x-axis\n",
        "    ax2 = ax1.twiny()\n",
        "    newlabel = list(range(num_epochs+1))\n",
        "\n",
        "    newpos = [e*iter_per_epoch for e in newlabel]\n",
        "\n",
        "    ax2.set_xticks(newpos[::10])\n",
        "    ax2.set_xticklabels(newlabel[::10])\n",
        "\n",
        "    ax2.xaxis.set_ticks_position('bottom')\n",
        "    ax2.xaxis.set_label_position('bottom')\n",
        "    ax2.spines['bottom'].set_position(('outward', 45))\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_xlim(ax1.get_xlim())\n",
        "    ###################\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if results_dir is not None:\n",
        "        image_path = os.path.join(results_dir, 'plot_training_loss.pdf')\n",
        "        plt.savefig(image_path)\n",
        "\n",
        "\n",
        "def plot_accuracy(train_acc_list, valid_acc_list, results_dir):\n",
        "\n",
        "    num_epochs = len(train_acc_list)\n",
        "\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             train_acc_list, label='Training')\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             valid_acc_list, label='Validation')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if results_dir is not None:\n",
        "        image_path = os.path.join(\n",
        "            results_dir, 'plot_acc_training_validation.pdf')\n",
        "        plt.savefig(image_path)\n"
      ],
      "metadata": {
        "id": "15hbXktfKbeM"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_grdW3pxCzz"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "nQIUm5EjxFNa"
      },
      "outputs": [],
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "        \n",
        "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
        "                                 hidden_dim)        \n",
        "        \n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "\n",
        "    def forward(self, text):\n",
        "        # text dim: [sentence length, batch size]        \n",
        "        embedded = self.embedding(text)\n",
        "        # embedded dim: [sentence length, batch size, embedding dim]\n",
        "        \n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        # output dim: [sentence length, batch size, hidden dim]\n",
        "        # hidden dim: [1, batch size, hidden dim]\n",
        "\n",
        "        hidden.squeeze_(0)\n",
        "        # hidden dim: [batch size, hidden dim]\n",
        "        \n",
        "        output = self.fc(hidden)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and plot the results"
      ],
      "metadata": {
        "id": "RZYw-Aa6M2od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(input_dim=len(vocab),\n",
        "             embedding_dim=EMBEDDING_DIM,\n",
        "             hidden_dim=HIDDEN_DIM,\n",
        "             output_dim=NUM_CLASSES # could use 1 for binary classification\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       verbose=True)\n",
        "\n",
        "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
        "    model=model,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    test_loader=test_loader,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    logging_interval=100)\n",
        "\n"
      ],
      "metadata": {
        "id": "SJsC5jzkMe6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
        "                   num_epochs=NUM_EPOCHS,\n",
        "                   iter_per_epoch=len(train_loader),\n",
        "                   results_dir=None,\n",
        "                   averaging_iterations=100)\n",
        "plt.ylim([0.5, 1])\n",
        "plt.show()\n",
        "\n",
        "plot_accuracy(train_acc_list=train_acc_list,\n",
        "              valid_acc_list=valid_acc_list,\n",
        "              results_dir=None)\n",
        "plt.ylim([40, 60])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QVwYR4zKiH9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, sentence):\n",
        "\n",
        "    model.eval()\n",
        "    tokenized = tokenizer(sentence)\n",
        "    indexed = [vocab[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = F.softmax(model(tensor), dim=1)\n",
        "    return prediction.to(\"cpu\").squeeze(dim=0).detach().numpy()\n",
        "\n",
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"This is such an awesome movie, I really love it!\")[1]\n"
      ],
      "metadata": {
        "id": "V3Z8HBMZkWG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Probability negative:')\n",
        "predict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")[0]"
      ],
      "metadata": {
        "id": "jS-4s-9bk_oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lRusB3dF80X"
      },
      "outputs": [],
      "source": [
        "%watermark -iv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "rnn_lstm_packed_imdb.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}