{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrei-radulescu-banu/stat453-deep-learning-ss21/blob/main/L15/packed_lstm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch==1.13.0 torchtext==0.14.0 torchdata==0.5.0\n",
        "\n",
        "# Reload environment\n",
        "exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quCeAViQxtFC",
        "outputId": "1bd16c0e-03c7-44aa-c789-0554a5ebb87e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchtext==0.14.0 in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Requirement already satisfied: torchdata==0.5.0 in /usr/local/lib/python3.8/dist-packages (0.5.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0) (4.4.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (4.64.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (1.21.6)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.8/dist-packages (from torchdata==0.5.0) (1.25.11)\n",
            "Requirement already satisfied: portalocker>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from torchdata==0.5.0) (2.6.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (2022.9.24)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (3.0.4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kiY4tZXm7Gz"
      },
      "source": [
        "Derived from:\n",
        "STAT 453: Deep Learning (Spring 2021)  \n",
        "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
        "Lecture 15: Introduction to recurrent neural networks\n",
        "\n",
        "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n",
        "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21  \n",
        "Andrei's fork: https://github.com/andrei-radulescu-banu/stat453-deep-learning-ss21\n",
        "\n",
        "Ported by Andrei R-B to torchtext 0.14.0, using new DataPipes.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install watermark"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxYMCgA_nBvP",
        "outputId": "abc860c4-6d4f-448e-bf7a-2bdac7c8fef1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: watermark in /usr/local/lib/python3.8/dist-packages (2.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from watermark) (7.9.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.2.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (57.4.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: jedi>=0.10 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.18.2)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (5.6.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (2.0.10)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->watermark) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->watermark) (0.7.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4SK0xKAJgm"
      },
      "source": [
        "# RNN Classifier with LSTM Trained on Own Dataset (IMDB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc6xejhY-NzZ"
      },
      "source": [
        "Example notebook showing how to use an own CSV text dataset for training a simple RNN for sentiment classification (here: a binary classification problem with two labels, positive and negative) using LSTM (Long Short Term Memory) cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "moNmVfuvnImW"
      },
      "outputs": [],
      "source": [
        "%load_ext watermark\n",
        "%watermark -a 'Sebastian Raschka, Andrei R-B' -v -p torch,torchtext\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSRL42Qgy8I8"
      },
      "source": [
        "## General Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OvW1RgfepCBq"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "VOCABULARY_SIZE = 20000\n",
        "LEARNING_RATE = 0.005\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 15\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQMmKUEisW4W"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHwOuk54m7G6"
      },
      "source": [
        "The following cells will download the IMDB movie review dataset (http://ai.stanford.edu/~amaas/data/sentiment/) for positive-negative sentiment classification in as CSV-formatted file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7Kq0XWHom7G6"
      },
      "outputs": [],
      "source": [
        "!wget https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hXwZGkBQm7G7"
      },
      "outputs": [],
      "source": [
        "!gunzip -f movie_data.csv.gz "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGreVqRDm7G7"
      },
      "source": [
        "Check that the dataset looks okay:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uVr6xN53m7G8"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('movie_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "TCYKMce_m7G9"
      },
      "source": [
        "df.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']\n",
        "df.to_csv('movie_data.csv', index=None)\n",
        "\n",
        "df = pd.read_csv('movie_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ayCZ1etlm7G9"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJJJ1LtSm7G9"
      },
      "source": [
        "## Prepare Dataset with Torchdata and the new DataPipes API"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchdata.datapipes.iter import IterableWrapper, FileOpener\n",
        "datapipe = IterableWrapper([\"movie_data.csv\"])\n",
        "datapipe = FileOpener(datapipe, mode='b')\n",
        "datapipe = datapipe.parse_csv(skip_lines=1)\n",
        "\n",
        "for sample in datapipe:\n",
        "     print(sample)\n",
        "     break"
      ],
      "metadata": {
        "id": "A7Ue2q-1kwIj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset into Train/Validation/Test"
      ],
      "metadata": {
        "id": "uuDLF9BA4fuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into training, validation, and test partitions:"
      ],
      "metadata": {
        "id": "FxH6EdtA5CU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows in dataset\n",
        "N_ROWS = len(list(datapipe))  # 50000\n",
        "\n",
        "# Split into training and val datapipes early on. Will build vocabulary from training datapipe only.\n",
        "train_dp, valid_dp, test_dp = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"valid\": 0.1, \"test\": 0.1}, seed=0)\n",
        "\n",
        "print(f'Num Train: {len(train_dp)}')\n",
        "print(f'Num Validate: {len(valid_dp)}')\n",
        "print(f'Num Test: {len(test_dp)}')"
      ],
      "metadata": {
        "id": "We2S_UwOsroc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Vocabulary"
      ],
      "metadata": {
        "id": "RDIpnTf14KmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the vocabulary based on the top `VOCABULARY_SIZE` words. **build_vocab_from_iterator()** collects the most frequent tokens from the iterator **yield_tokens(train_datapipe)**, and adds special tokens at the begginning w/o changing the order of supplied tokens.\n"
      ],
      "metadata": {
        "id": "jRCjbUQK5q1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# See tutorial at https://www.youtube.com/watch?v=CrS-LFXEiyk\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text, _ in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "def get_vocab(train_datapipe):\n",
        "    vocab = build_vocab_from_iterator(yield_tokens(train_datapipe), specials=[\"<UNK>\", \"<PAD>\"], max_tokens=VOCABULARY_SIZE)\n",
        "    vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "aPC6DfASsZrl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the vocabulary**"
      ],
      "metadata": {
        "id": "wDgg4ub_9zgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = get_vocab(train_dp)\n",
        "print(\"Vocabulary size: \", len(vocab))"
      ],
      "metadata": {
        "id": "PeyMOsYiUhGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokens corresponding to the first 10 indices (0, 1, ..., 9):**"
      ],
      "metadata": {
        "id": "_3N2yVlx78fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab.get_itos()[:10]) # itos = integer-to-string"
      ],
      "metadata": {
        "id": "RbguzRrs7781"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch RNNs can deal with arbitrary lengths due to dynamic graphs, but padding is necessary for padding sequences to the same length in a given minibatch so we can store those in an array."
      ],
      "metadata": {
        "id": "3J1xW7i46Luz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting a string to an integer:**"
      ],
      "metadata": {
        "id": "FQusdyKM9df0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A direct way\n",
        "print(f\"the: {vocab['the']}\")\n",
        "\n",
        "# And an indirect way, using get_stoi() to get a dictionary of tokens and values\n",
        "print(f\"the: {vocab.get_stoi()['the']}\") # stoi = string-to-integer\n",
        "\n",
        "# What is the padding value?\n",
        "print(f\"<PAD>: {vocab['<PAD>']}\")\n",
        "PADDING_VALUE=vocab['<PAD>']"
      ],
      "metadata": {
        "id": "2Ipkzrhr770W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How are unknown tokens handled?**"
      ],
      "metadata": {
        "id": "UyeWI9Ci-evW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Default index: {vocab.get_default_index()}\")\n",
        "\n",
        "# Value of unknown token is default index when referenced with [] brackets:\n",
        "vocab['123aaa']"
      ],
      "metadata": {
        "id": "Nl_nM0r3699R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both `text_transform` and `label_transform` are the callable object, such as a lambda func here, to process the raw text and label data from the dataset iterators."
      ],
      "metadata": {
        "id": "6bk05mhx_xUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "label_transform = lambda x: 1 if x == '1' else 0\n",
        "\n",
        "# Print out the output of text_transform\n",
        "print(\"input to the text_transform:\", \"here is an example\")\n",
        "print(\"output of the text_transform:\", text_transform(\"here is an example\"))"
      ],
      "metadata": {
        "id": "BLTO10Ha_ygS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How do I convert an array of integers to the corresponding tokens?**"
      ],
      "metadata": {
        "id": "aMrQ41cEKszo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_itos = vocab.get_itos()\n",
        "vec_vocab_itos = np.vectorize(lambda x: vocab_itos[x])\n",
        "vec_vocab_itos([1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "id": "XIBt3bdlKr1t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Data Loaders"
      ],
      "metadata": {
        "id": "5ohB-Ern-AmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.utils.data.DataLoader` is used to generate data batch. Users could customize the data batch by defining a function with the `collate_fn` argument in the DataLoader. Here, in the `collate_batch` func, we process the raw text data and add padding to dynamically match the longest sentence in a batch."
      ],
      "metadata": {
        "id": "PnyQAEm4_D9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "def collate_batch(batch):\n",
        "   text_list, label_list = [], []\n",
        "   for (_text, _label) in batch:\n",
        "        label_list.append(label_transform(_label))\n",
        "        processed_text = torch.tensor(text_transform(_text))\n",
        "        text_list.append(processed_text)\n",
        "   return pad_sequence(text_list, padding_value=PADDING_VALUE).to(DEVICE), torch.tensor(label_list).to(DEVICE)"
      ],
      "metadata": {
        "id": "uFAZeWDa_H1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To group the texts with similar length together, like introduced in the legacy `BucketIterator` class, first of all, we randomly create multiple \"pools\", and each of them has a size of `batch_size * 100`. Then, we sort the samples within the individual pool by length. This idea can be implemented succintly through `batch_sampler` argument of PyTorch `Dataloader`. `batch_sampler` accepts 'Sampler' or Iterable object that yields indices of next batch. In the code below, we implemented a generator that yields batch of indices for which the corresponding batch of data is of similar length. "
      ],
      "metadata": {
        "id": "PPVGxmEsCR6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = list(train_dp)\n",
        "\n",
        "def batch_sampler():\n",
        "    indices = [(i, len(tokenizer(s[0]))) for i, s in enumerate(train_list)]\n",
        "    random.shuffle(indices)\n",
        "    pooled_indices = []\n",
        "    # create pool of indices with similar lengths \n",
        "    for i in range(0, len(indices), BATCH_SIZE * 100): \n",
        "       pooled_indices.extend(sorted(indices[i:i + BATCH_SIZE * 100], key=lambda x: x[0]))\n",
        "\n",
        "    pooled_indices = [x[1] for x in pooled_indices]\n",
        "\n",
        "    # yield indices for current batch\n",
        "    for i in range(0, len(pooled_indices), BATCH_SIZE):\n",
        "        yield pooled_indices[i:i + BATCH_SIZE]"
      ],
      "metadata": {
        "id": "eH4w2xp3CcA_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = DataLoader(list(train_dp), batch_sampler=batch_sampler(), shuffle=True, \n",
        "                          collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(list(valid_dp), batch_sampler=batch_sampler(), shuffle=True, \n",
        "                          collate_fn=collate_batch)\n",
        "test_loader = DataLoader(list(test_dp), batch_sampler=batch_sampler(), shuffle=True, \n",
        "                         collate_fn=collate_batch)\n",
        "\n",
        "\n",
        "text_batch, label_batch = next(iter(train_loader))\n",
        "print(text_batch.size())\n",
        "print(label_batch.size())"
      ],
      "metadata": {
        "id": "izH5UueztrRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the iterators (note that the number of rows depends on the longest document in the respective batch):"
      ],
      "metadata": {
        "id": "alhb-l3CSvO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train')\n",
        "for text_batch, label_batch in train_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nValid:')\n",
        "for text_batch, label_batch in valid_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nTest:')\n",
        "for text_batch, label_batch in test_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break"
      ],
      "metadata": {
        "id": "4P65G4zqS1qk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The text batch as indices of tokens**"
      ],
      "metadata": {
        "id": "5BcP4qmAOSGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_batch)"
      ],
      "metadata": {
        "id": "oPee-HP-MusQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The corresponding vocabulary tokens**\n",
        "\n",
        "Notice how the reviews appear on the tensor columns. Each column has one review."
      ],
      "metadata": {
        "id": "epUvW9z5OYgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec_vocab_itos(text_batch.to(\"cpu\")))"
      ],
      "metadata": {
        "id": "siH213KBMx2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**And the batch labels**\n",
        "\n",
        "Each element is the review score for the corresponding column."
      ],
      "metadata": {
        "id": "0Pjzqxv1OeBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_batch)"
      ],
      "metadata": {
        "id": "J5NR0SlxN1Qh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The next batch will have different text column size.**\n",
        "\n",
        "The column size is determined by the max length of reviews in a batch. Each batch has a different text column size."
      ],
      "metadata": {
        "id": "SbKYBRznQgi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch, label_batch = next(iter(train_loader))\n",
        "print(f'Text matrix size: {text_batch.size()}')\n",
        "print(f'Target vector size: {label_batch.size()}')\n",
        "\n",
        "text_batch, label_batch = next(iter(train_loader))\n",
        "print(f'Text matrix size: {text_batch.size()}')\n",
        "print(f'Target vector size: {label_batch.size()}')"
      ],
      "metadata": {
        "id": "RFpzgfY5Qfnv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec_vocab_itos(text_batch.to(\"cpu\")))"
      ],
      "metadata": {
        "id": "BopSzNUXRIOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_batch)"
      ],
      "metadata": {
        "id": "yDM8DBXkRJjy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utility Functions"
      ],
      "metadata": {
        "id": "YDm8DtLzKR79"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Compute model accuracy on a dataloader**\n",
        "\n",
        "Pass the train, valid or test dataloader\n"
      ],
      "metadata": {
        "id": "wfFF6KruLaZ_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T5t1Afn4xO11"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.float().to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Train a model**\n",
        "\n",
        "This is model- and dataloader-independent."
      ],
      "metadata": {
        "id": "5a24JY8bLmX6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, num_epochs, train_loader,\n",
        "                valid_loader, test_loader, optimizer,\n",
        "                device, logging_interval=50,\n",
        "                scheduler=None,\n",
        "                scheduler_on='valid_acc'):\n",
        "\n",
        "    start_time = time.time()\n",
        "    minibatch_loss_list, train_acc_list, valid_acc_list = [], [], []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "\n",
        "        model.train()\n",
        "        for batch_idx, (features, targets) in enumerate(train_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # ## FORWARD AND BACK PROP\n",
        "            logits = model(features)\n",
        "            loss = torch.nn.functional.cross_entropy(logits, targets)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            loss.backward()\n",
        "\n",
        "            # ## UPDATE MODEL PARAMETERS\n",
        "            optimizer.step()\n",
        "\n",
        "            # ## LOGGING\n",
        "            minibatch_loss_list.append(loss.item())\n",
        "            if not batch_idx % logging_interval:\n",
        "                print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                      f'| Batch {batch_idx:04d}/{len(train_loader):04d} '\n",
        "                      f'| Loss: {loss:.4f}')\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():  # save memory during inference\n",
        "            train_acc = compute_accuracy(model, train_loader, device=device)\n",
        "            valid_acc = compute_accuracy(model, valid_loader, device=device)\n",
        "            print(f'Epoch: {epoch+1:03d}/{num_epochs:03d} '\n",
        "                  f'| Train: {train_acc :.2f}% '\n",
        "                  f'| Validation: {valid_acc :.2f}%')\n",
        "            train_acc_list.append(train_acc.item())\n",
        "            valid_acc_list.append(valid_acc.item())\n",
        "\n",
        "        elapsed = (time.time() - start_time)/60\n",
        "        print(f'Time elapsed: {elapsed:.2f} min')\n",
        "        \n",
        "        if scheduler is not None:\n",
        "\n",
        "            if scheduler_on == 'valid_acc':\n",
        "                scheduler.step(valid_acc_list[-1])\n",
        "            elif scheduler_on == 'minibatch_loss':\n",
        "                scheduler.step(minibatch_loss_list[-1])\n",
        "            else:\n",
        "                raise ValueError(f'Invalid `scheduler_on` choice.')\n",
        "        \n",
        "\n",
        "    elapsed = (time.time() - start_time)/60\n",
        "    print(f'Total Training Time: {elapsed:.2f} min')\n",
        "\n",
        "    test_acc = compute_accuracy(model, test_loader, device=device)\n",
        "    print(f'Test accuracy {test_acc :.2f}%')\n",
        "\n",
        "    return minibatch_loss_list, train_acc_list, valid_acc_list\n"
      ],
      "metadata": {
        "id": "RYnX6OzjLAYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Plot training loss and accuracy**"
      ],
      "metadata": {
        "id": "DhFkZG_3Lxyn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_training_loss(minibatch_loss_list, num_epochs, iter_per_epoch,\n",
        "                       results_dir=None, averaging_iterations=100):\n",
        "\n",
        "    plt.figure()\n",
        "    ax1 = plt.subplot(1, 1, 1)\n",
        "    ax1.plot(range(len(minibatch_loss_list)),\n",
        "             (minibatch_loss_list), label='Minibatch Loss')\n",
        "\n",
        "    if len(minibatch_loss_list) > 1000:\n",
        "        ax1.set_ylim([\n",
        "            0, np.max(minibatch_loss_list[1000:])*1.5\n",
        "            ])\n",
        "    ax1.set_xlabel('Iterations')\n",
        "    ax1.set_ylabel('Loss')\n",
        "\n",
        "    ax1.plot(np.convolve(minibatch_loss_list,\n",
        "                         np.ones(averaging_iterations,)/averaging_iterations,\n",
        "                         mode='valid'),\n",
        "             label='Running Average')\n",
        "    ax1.legend()\n",
        "\n",
        "    ###################\n",
        "    # Set scond x-axis\n",
        "    ax2 = ax1.twiny()\n",
        "    newlabel = list(range(num_epochs+1))\n",
        "\n",
        "    newpos = [e*iter_per_epoch for e in newlabel]\n",
        "\n",
        "    ax2.set_xticks(newpos[::10])\n",
        "    ax2.set_xticklabels(newlabel[::10])\n",
        "\n",
        "    ax2.xaxis.set_ticks_position('bottom')\n",
        "    ax2.xaxis.set_label_position('bottom')\n",
        "    ax2.spines['bottom'].set_position(('outward', 45))\n",
        "    ax2.set_xlabel('Epochs')\n",
        "    ax2.set_xlim(ax1.get_xlim())\n",
        "    ###################\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if results_dir is not None:\n",
        "        image_path = os.path.join(results_dir, 'plot_training_loss.pdf')\n",
        "        plt.savefig(image_path)\n",
        "\n",
        "\n",
        "def plot_accuracy(train_acc_list, valid_acc_list, results_dir):\n",
        "\n",
        "    num_epochs = len(train_acc_list)\n",
        "\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             train_acc_list, label='Training')\n",
        "    plt.plot(np.arange(1, num_epochs+1),\n",
        "             valid_acc_list, label='Validation')\n",
        "\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "\n",
        "    if results_dir is not None:\n",
        "        image_path = os.path.join(\n",
        "            results_dir, 'plot_acc_training_validation.pdf')\n",
        "        plt.savefig(image_path)\n"
      ],
      "metadata": {
        "id": "15hbXktfKbeM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_grdW3pxCzz"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQIUm5EjxFNa"
      },
      "outputs": [],
      "source": [
        "class LSTM(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "        #self.rnn = torch.nn.RNN(embedding_dim,\n",
        "        #                        hidden_dim,\n",
        "        #                        nonlinearity='relu')\n",
        "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
        "                                 hidden_dim)        \n",
        "        \n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "\n",
        "    def forward(self, text):\n",
        "        # text dim: [sentence length, batch size]        \n",
        "        embedded = self.embedding(text)\n",
        "        # embedded dim: [sentence length, batch size, embedding dim]\n",
        "        \n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        # output dim: [sentence length, batch size, hidden dim]\n",
        "        # hidden dim: [1, batch size, hidden dim]\n",
        "\n",
        "        hidden.squeeze_(0)\n",
        "        # hidden dim: [batch size, hidden dim]\n",
        "        \n",
        "        output = self.fc(hidden)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train and plot the results"
      ],
      "metadata": {
        "id": "RZYw-Aa6M2od"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LSTM(input_dim=len(vocab),\n",
        "             embedding_dim=EMBEDDING_DIM,\n",
        "             hidden_dim=HIDDEN_DIM,\n",
        "             output_dim=NUM_CLASSES # could use 1 for binary classification\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer,\n",
        "                                                       factor=0.1,\n",
        "                                                       mode='max',\n",
        "                                                       verbose=True)\n",
        "\n",
        "minibatch_loss_list, train_acc_list, valid_acc_list = train_model(\n",
        "    model=model,\n",
        "    num_epochs=NUM_EPOCHS,\n",
        "    train_loader=train_loader,\n",
        "    valid_loader=valid_loader,\n",
        "    test_loader=test_loader,\n",
        "    optimizer=optimizer,\n",
        "    device=DEVICE,\n",
        "    logging_interval=100)\n",
        "\n"
      ],
      "metadata": {
        "id": "SJsC5jzkMe6_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_training_loss(minibatch_loss_list=minibatch_loss_list,\n",
        "                   num_epochs=NUM_EPOCHS,\n",
        "                   iter_per_epoch=len(train_loader),\n",
        "                   results_dir=None,\n",
        "                   averaging_iterations=100)\n",
        "plt.ylim([0.5, 1])\n",
        "plt.show()\n",
        "\n",
        "plot_accuracy(train_acc_list=train_acc_list,\n",
        "              valid_acc_list=valid_acc_list,\n",
        "              results_dir=None)\n",
        "plt.ylim([40, 60])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "QVwYR4zKiH9l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, sentence):\n",
        "\n",
        "    model.eval()\n",
        "    tokenized = tokenizer(sentence)\n",
        "    indexed = [vocab[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = F.softmax(model(tensor), dim=1)\n",
        "    return prediction.to(\"cpu\").squeeze(dim=0).detach().numpy()\n",
        "\n",
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"This is such an awesome movie, I really love it!\")[1]\n"
      ],
      "metadata": {
        "id": "V3Z8HBMZkWG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('Probability negative:')\n",
        "predict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")[0]"
      ],
      "metadata": {
        "id": "jS-4s-9bk_oo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7lRusB3dF80X"
      },
      "outputs": [],
      "source": [
        "%watermark -iv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "rnn_lstm_packed_imdb.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}