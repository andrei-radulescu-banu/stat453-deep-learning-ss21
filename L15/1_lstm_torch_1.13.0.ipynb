{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrei-radulescu-banu/stat453-deep-learning-ss21/blob/main/L15/1_lstm_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U torch==1.13.0 torchtext==0.14.0 torchdata==0.5.0\n",
        "\n",
        "# Reload environment\n",
        "exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "quCeAViQxtFC",
        "outputId": "ded68056-9ba9-4d1f-d1ec-f39fc8f6b578"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch==1.13.0 in /usr/local/lib/python3.8/dist-packages (1.13.0+cu116)\n",
            "Requirement already satisfied: torchtext==0.14.0 in /usr/local/lib/python3.8/dist-packages (0.14.0)\n",
            "Collecting torchdata==0.5.0\n",
            "  Downloading torchdata-0.5.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 4.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch==1.13.0) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (1.21.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (2.23.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.8/dist-packages (from torchtext==0.14.0) (4.64.1)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.26.13-py2.py3-none-any.whl (140 kB)\n",
            "\u001b[K     |████████████████████████████████| 140 kB 76.0 MB/s \n",
            "\u001b[?25hCollecting portalocker>=2.0.0\n",
            "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting urllib3>=1.25\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 64.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (2022.9.24)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests->torchtext==0.14.0) (2.10)\n",
            "Installing collected packages: urllib3, portalocker, torchdata\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "Successfully installed portalocker-2.6.0 torchdata-0.5.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1kiY4tZXm7Gz"
      },
      "source": [
        "Original source:\n",
        "STAT 453: Deep Learning (Spring 2021)  \n",
        "Instructor: Sebastian Raschka (sraschka@wisc.edu)  \n",
        "\n",
        "Course website: http://pages.stat.wisc.edu/~sraschka/teaching/stat453-ss2021/  \n",
        "GitHub repository: https://github.com/rasbt/stat453-deep-learning-ss21\n",
        "\n",
        "Ported by Andrei R-B to torchtext 0.14.0\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install watermark\n",
        "!pip install colab-env --upgrade\n",
        "import colab_env\n",
        "colab_env.envvar_handler.add_env(\"CUBLAS_WORKSPACE_CONFIG\", \":4096:8\", overwrite=True)\n",
        "!git clone https://github.com/andrei-radulescu-banu/stat453-deep-learning-ss21.git\n",
        "import sys, os\n",
        "sys.path.append(\"/content/stat453-deep-learning-ss21/L15\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxYMCgA_nBvP",
        "outputId": "1bcf41ae-dc82-4955-af74-d4044cd4d98d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting watermark\n",
            "  Downloading watermark-2.3.1-py2.py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from watermark) (7.9.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (0.2.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (5.6.0)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.6 MB 4.5 MB/s \n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (2.0.10)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->watermark) (4.8.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->watermark) (0.8.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->watermark) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->watermark) (0.7.0)\n",
            "Installing collected packages: jedi, watermark\n",
            "Successfully installed jedi-0.18.2 watermark-2.3.1\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting colab-env\n",
            "  Downloading colab-env-0.2.0.tar.gz (4.7 kB)\n",
            "Collecting python-dotenv<1.0,>=0.10.0\n",
            "  Downloading python_dotenv-0.21.0-py3-none-any.whl (18 kB)\n",
            "Building wheels for collected packages: colab-env\n",
            "  Building wheel for colab-env (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for colab-env: filename=colab_env-0.2.0-py3-none-any.whl size=3837 sha256=fc953a3cf3d36d43a40c0e362d1a436421baeebb2aa5d65352b87adfed3d7859\n",
            "  Stored in directory: /root/.cache/pip/wheels/1c/65/0c/5552431f2622d6e0283e3dba61c6837103a9cbdbd89b7b0cba\n",
            "Successfully built colab-env\n",
            "Installing collected packages: python-dotenv, colab-env\n",
            "Successfully installed colab-env-0.2.0 python-dotenv-0.21.0\n",
            "Mounted at /content/gdrive\n",
            "Cloning into 'stat453-deep-learning-ss21'...\n",
            "remote: Enumerating objects: 1331, done.\u001b[K\n",
            "remote: Counting objects: 100% (281/281), done.\u001b[K\n",
            "remote: Compressing objects: 100% (124/124), done.\u001b[K\n",
            "remote: Total 1331 (delta 197), reused 179 (delta 135), pack-reused 1050\u001b[K\n",
            "Receiving objects: 100% (1331/1331), 116.94 MiB | 35.98 MiB/s, done.\n",
            "Resolving deltas: 100% (301/301), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vY4SK0xKAJgm"
      },
      "source": [
        "# RNN Classifier with LSTM Trained on Own Dataset (IMDB)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sc6xejhY-NzZ"
      },
      "source": [
        "Example notebook showing how to use an own CSV text dataset for training a simple RNN for sentiment classification (here: a binary classification problem with two labels, positive and negative) using LSTM (Long Short Term Memory) cells."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moNmVfuvnImW",
        "outputId": "90fa2028-acc8-49b7-94f9-dd12bfb83183"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The watermark extension is already loaded. To reload it, use:\n",
            "  %reload_ext watermark\n",
            "Author: Sebastian Raschka\n",
            "\n",
            "Python implementation: CPython\n",
            "Python version       : 3.8.16\n",
            "IPython version      : 7.9.0\n",
            "\n",
            "torch    : 1.13.0+cu116\n",
            "torchtext: 0.14.0\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%load_ext watermark\n",
        "%watermark -a 'Sebastian Raschka' -v -p torch,torchtext\n",
        "\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchtext\n",
        "import time\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "torch.backends.cudnn.deterministic = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GSRL42Qgy8I8"
      },
      "source": [
        "## General Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "OvW1RgfepCBq"
      },
      "outputs": [],
      "source": [
        "RANDOM_SEED = 123\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "\n",
        "VOCABULARY_SIZE = 20000\n",
        "LEARNING_RATE = 0.005\n",
        "BATCH_SIZE = 128\n",
        "NUM_EPOCHS = 15\n",
        "DEVICE = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "EMBEDDING_DIM = 128\n",
        "HIDDEN_DIM = 256\n",
        "NUM_CLASSES = 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mQMmKUEisW4W"
      },
      "source": [
        "## Download Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tHwOuk54m7G6"
      },
      "source": [
        "The following cells will download the IMDB movie review dataset (http://ai.stanford.edu/~amaas/data/sentiment/) for positive-negative sentiment classification in as CSV-formatted file:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Kq0XWHom7G6",
        "outputId": "ff29607d-9dd5-48dd-c227-7031f19c54f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-12-10 11:59:42--  https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz [following]\n",
            "--2022-12-10 11:59:43--  https://raw.githubusercontent.com/rasbt/python-machine-learning-book-3rd-edition/master/ch08/movie_data.csv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26521894 (25M) [application/octet-stream]\n",
            "Saving to: ‘movie_data.csv.gz’\n",
            "\n",
            "movie_data.csv.gz   100%[===================>]  25.29M   156MB/s    in 0.2s    \n",
            "\n",
            "2022-12-10 11:59:43 (156 MB/s) - ‘movie_data.csv.gz’ saved [26521894/26521894]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://github.com/rasbt/python-machine-learning-book-3rd-edition/raw/master/ch08/movie_data.csv.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "hXwZGkBQm7G7"
      },
      "outputs": [],
      "source": [
        "!gunzip -f movie_data.csv.gz "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wGreVqRDm7G7"
      },
      "source": [
        "Check that the dataset looks okay:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 698
        },
        "id": "uVr6xN53m7G8",
        "outputId": "f282f4a4-0daf-4731-b140-9c734f6769d5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                              review  sentiment\n",
              "0  In 1974, the teenager Martha Moxley (Maggie Gr...          1\n",
              "1  OK... so... I really like Kris Kristofferson a...          0\n",
              "2  ***SPOILER*** Do not read this, if you think a...          0\n",
              "3  hi for all the people who have seen this wonde...          1\n",
              "4  I recently bought the DVD, forgetting just how...          0"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-904c3574-4931-43e8-850b-14277f90d0f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>In 1974, the teenager Martha Moxley (Maggie Gr...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>OK... so... I really like Kris Kristofferson a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>***SPOILER*** Do not read this, if you think a...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>hi for all the people who have seen this wonde...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>I recently bought the DVD, forgetting just how...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-904c3574-4931-43e8-850b-14277f90d0f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-904c3574-4931-43e8-850b-14277f90d0f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-904c3574-4931-43e8-850b-14277f90d0f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "df = pd.read_csv('movie_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "TCYKMce_m7G9"
      },
      "source": [
        "df.columns = ['TEXT_COLUMN_NAME', 'LABEL_COLUMN_NAME']\n",
        "df.to_csv('movie_data.csv', index=None)\n",
        "\n",
        "df = pd.read_csv('movie_data.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "ayCZ1etlm7G9"
      },
      "outputs": [],
      "source": [
        "del df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJJJ1LtSm7G9"
      },
      "source": [
        "## Prepare Dataset with Torchdata and the new DataPipes API"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torchdata.datapipes.iter import IterableWrapper, FileOpener\n",
        "datapipe = IterableWrapper([\"movie_data.csv\"])\n",
        "datapipe = FileOpener(datapipe, mode='b')\n",
        "datapipe = datapipe.parse_csv(skip_lines=1)\n",
        "\n",
        "for sample in datapipe:\n",
        "     print(sample)\n",
        "     break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7Ue2q-1kwIj",
        "outputId": "fb4e00c3-3972-452a-c5cc-e7333463e27a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['In 1974, the teenager Martha Moxley (Maggie Grace) moves to the high-class area of Belle Haven, Greenwich, Connecticut. On the Mischief Night, eve of Halloween, she was murdered in the backyard of her house and her murder remained unsolved. Twenty-two years later, the writer Mark Fuhrman (Christopher Meloni), who is a former LA detective that has fallen in disgrace for perjury in O.J. Simpson trial and moved to Idaho, decides to investigate the case with his partner Stephen Weeks (Andrew Mitchell) with the purpose of writing a book. The locals squirm and do not welcome them, but with the support of the retired detective Steve Carroll (Robert Forster) that was in charge of the investigation in the 70\\'s, they discover the criminal and a net of power and money to cover the murder.<br /><br />\"Murder in Greenwich\" is a good TV movie, with the true story of a murder of a fifteen years old girl that was committed by a wealthy teenager whose mother was a Kennedy. The powerful and rich family used their influence to cover the murder for more than twenty years. However, a snoopy detective and convicted perjurer in disgrace was able to disclose how the hideous crime was committed. The screenplay shows the investigation of Mark and the last days of Martha in parallel, but there is a lack of the emotion in the dramatization. My vote is seven.<br /><br />Title (Brazil): Not Available', '1']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split Dataset into Train/Validation/Test"
      ],
      "metadata": {
        "id": "uuDLF9BA4fuX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split the dataset into training, validation, and test partitions:"
      ],
      "metadata": {
        "id": "FxH6EdtA5CU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the number of rows in dataset\n",
        "N_ROWS = len(list(datapipe))  # 50000\n",
        "\n",
        "# Split into training and val datapipes early on. Will build vocabulary from training datapipe only.\n",
        "train_dp, valid_dp, test_dp = datapipe.random_split(total_length=N_ROWS, weights={\"train\": 0.8, \"valid\": 0.1, \"test\": 0.1}, seed=0)\n",
        "\n",
        "print(f'Num Train: {len(train_dp)}')\n",
        "print(f'Num Validate: {len(valid_dp)}')\n",
        "print(f'Num Test: {len(test_dp)}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "We2S_UwOsroc",
        "outputId": "1b0edec8-7934-44f4-b7a6-7ad3ab807690"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Num Train: 40000\n",
            "Num Validate: 5000\n",
            "Num Test: 5000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build the Vocabulary"
      ],
      "metadata": {
        "id": "RDIpnTf14KmZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build the vocabulary based on the top `VOCABULARY_SIZE` words. **build_vocab_from_iterator()** collects the most frequent tokens from the iterator **yield_tokens(train_datapipe)**, and adds special tokens at the begginning w/o changing the order of supplied tokens.\n"
      ],
      "metadata": {
        "id": "jRCjbUQK5q1j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torchtext.vocab import build_vocab_from_iterator\n",
        "from torchtext.data.utils import get_tokenizer\n",
        "\n",
        "# See tutorial at https://www.youtube.com/watch?v=CrS-LFXEiyk\n",
        "tokenizer = get_tokenizer(\"basic_english\")\n",
        "\n",
        "def yield_tokens(data_iter):\n",
        "    for text, _ in data_iter:\n",
        "        yield tokenizer(text)\n",
        "\n",
        "def get_vocab(train_datapipe):\n",
        "    vocab = build_vocab_from_iterator(yield_tokens(train_datapipe), specials=[\"<UNK>\", \"<PAD>\"], max_tokens=VOCABULARY_SIZE)\n",
        "    vocab.set_default_index(vocab[\"<UNK>\"])\n",
        "    return vocab"
      ],
      "metadata": {
        "id": "aPC6DfASsZrl"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Build the vocabulary**"
      ],
      "metadata": {
        "id": "wDgg4ub_9zgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = get_vocab(train_dp)\n",
        "print(\"Vocabulary size: \", len(vocab))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PeyMOsYiUhGO",
        "outputId": "cf87f03e-3fdd-414a-d125-0ffcd4f1588d"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size:  20000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tokens corresponding to the first 10 indices (0, 1, ..., 9):**"
      ],
      "metadata": {
        "id": "_3N2yVlx78fM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vocab.get_itos()[:10]) # itos = integer-to-string"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RbguzRrs7781",
        "outputId": "90643703-9b8c-42c2-d318-b97916c8abdf"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<UNK>', '<PAD>', 'the', '.', ',', 'and', 'a', 'of', 'to', \"'\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "PyTorch RNNs can deal with arbitrary lengths due to dynamic graphs, but padding is necessary for padding sequences to the same length in a given minibatch so we can store those in an array."
      ],
      "metadata": {
        "id": "3J1xW7i46Luz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Converting a string to an integer:**"
      ],
      "metadata": {
        "id": "FQusdyKM9df0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# A direct way\n",
        "print(f\"the: {vocab['the']}\")\n",
        "\n",
        "# And an indirect way, using get_stoi() to get a dictionary of tokens and values\n",
        "print(f\"the: {vocab.get_stoi()['the']}\") # stoi = string-to-integer\n",
        "\n",
        "# What is the padding value?\n",
        "print(f\"<PAD>: {vocab['<PAD>']}\")\n",
        "PADDING_VALUE=vocab['<PAD>']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Ipkzrhr770W",
        "outputId": "d183ff91-e492-4825-ff4b-d37f9f7c309a"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the: 2\n",
            "the: 2\n",
            "<PAD>: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How are unknown tokens handled?**"
      ],
      "metadata": {
        "id": "UyeWI9Ci-evW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Default index: {vocab.get_default_index()}\")\n",
        "\n",
        "# Value of unknown token is default index when referenced with [] brackets:\n",
        "vocab['123aaa']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nl_nM0r3699R",
        "outputId": "f92e2869-0be0-429e-912f-c8ee967ef64e"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default index: 0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both `text_transform` and `label_transform` are the callable object, such as a lambda func here, to process the raw text and label data from the dataset iterators."
      ],
      "metadata": {
        "id": "6bk05mhx_xUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_transform = lambda x: [vocab[token] for token in tokenizer(x)]\n",
        "label_transform = lambda x: 1 if x == '1' else 0\n",
        "\n",
        "# Print out the output of text_transform\n",
        "print(\"input to the text_transform:\", \"here is an example\")\n",
        "print(\"output of the text_transform:\", text_transform(\"here is an example\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLTO10Ha_ygS",
        "outputId": "56f13f55-8421-4ca5-97d3-1aa5db0d6043"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input to the text_transform: here is an example\n",
            "output of the text_transform: [135, 10, 41, 476]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**How do I convert an array of integers to the corresponding tokens?**"
      ],
      "metadata": {
        "id": "aMrQ41cEKszo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_itos = vocab.get_itos()\n",
        "vec_vocab_itos = np.vectorize(lambda x: vocab_itos[x])\n",
        "vec_vocab_itos([1, 2, 3, 4, 5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XIBt3bdlKr1t",
        "outputId": "84371ef3-7db7-4876-cd74-303d35486dcf"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['<PAD>', 'the', '.', ',', 'and'], dtype='<U5')"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define Data Loaders"
      ],
      "metadata": {
        "id": "5ohB-Ern-AmJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`torch.utils.data.DataLoader` is used to generate data batch. Users could customize the data batch by defining a function with the `collate_fn` argument in the DataLoader. Here, in the `collate_batch` func, we process the raw text data and add padding to dynamically match the longest sentence in a batch."
      ],
      "metadata": {
        "id": "PnyQAEm4_D9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "import torch\n",
        "\n",
        "def collate_batch(batch):\n",
        "   text_list, label_list = [], []\n",
        "   for (_text, _label) in batch:\n",
        "        label_list.append(label_transform(_label))\n",
        "        processed_text = torch.tensor(text_transform(_text))\n",
        "        text_list.append(processed_text)\n",
        "   return pad_sequence(text_list, padding_value=PADDING_VALUE).to(DEVICE), torch.tensor(label_list).to(DEVICE)\n",
        "\n",
        "train_loader = DataLoader(list(train_dp), batch_size=BATCH_SIZE, shuffle=True, \n",
        "                          collate_fn=collate_batch)\n",
        "valid_loader = DataLoader(list(valid_dp), batch_size=BATCH_SIZE, shuffle=True, \n",
        "                          collate_fn=collate_batch)\n",
        "test_loader = DataLoader(list(test_dp), batch_size=BATCH_SIZE, shuffle=True, \n",
        "                         collate_fn=collate_batch)\n",
        "\n",
        "\n",
        "text_batch, label_batch = next(iter(train_dataloader))\n",
        "print(text_batch.size())\n",
        "print(label_batch.size())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uFAZeWDa_H1g",
        "outputId": "33830faf-3646-4db2-b000-05b7e765a167"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([850, 128])\n",
            "torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the iterators (note that the number of rows depends on the longest document in the respective batch):"
      ],
      "metadata": {
        "id": "alhb-l3CSvO1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print('Train')\n",
        "for text_batch, label_batch in train_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nValid:')\n",
        "for text_batch, label_batch in valid_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break\n",
        "    \n",
        "print('\\nTest:')\n",
        "for text_batch, label_batch in test_loader:\n",
        "    print(f'Text matrix size: {text_batch.size()}')\n",
        "    print(f'Target vector size: {label_batch.size()}')\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4P65G4zqS1qk",
        "outputId": "a9d31733-7342-4373-9ba3-8d9377118146"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train\n",
            "Text matrix size: torch.Size([935, 128])\n",
            "Target vector size: torch.Size([128])\n",
            "\n",
            "Valid:\n",
            "Text matrix size: torch.Size([1127, 128])\n",
            "Target vector size: torch.Size([128])\n",
            "\n",
            "Test:\n",
            "Text matrix size: torch.Size([879, 128])\n",
            "Target vector size: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The text batch as indices of tokens**"
      ],
      "metadata": {
        "id": "5BcP4qmAOSGC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(text_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oPee-HP-MusQ",
        "outputId": "bd7df008-570c-4a85-cfca-f462c1b9436f"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[8097,   76,   61,  ...,    2,    6,  249],\n",
            "        [1954,    5, 1321,  ...,  421,  582,   42],\n",
            "        [1694,   64,  324,  ...,    7,    0,  448],\n",
            "        ...,\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1],\n",
            "        [   1,    1,    1,  ...,    1,    1,    1]], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The corresponding vocabulary tokens**\n",
        "\n",
        "Notice how the reviews appear on the tensor columns. Each column has one review."
      ],
      "metadata": {
        "id": "epUvW9z5OYgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec_vocab_itos(text_batch.to(\"cpu\")))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siH213KBMx2O",
        "outputId": "68a29d47-51b3-4c96-f1ba-98bf76d04cea"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['alleged' 'me' 'very' ... 'the' 'a' 'anyone']\n",
            " ['scream' 'and' 'disappointing' ... 'title' 'particularly' 'who']\n",
            " ['queen' 'my' 'version' ... 'of' '<UNK>' 'loved']\n",
            " ...\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**And the batch labels**\n",
        "\n",
        "Each element is the review score for the corresponding column."
      ],
      "metadata": {
        "id": "0Pjzqxv1OeBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J5NR0SlxN1Qh",
        "outputId": "285406af-357b-452a-8365-59c4a1b78c61"
      },
      "execution_count": 134,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
            "        0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0,\n",
            "        1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0,\n",
            "        1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "        0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
            "        1, 1, 0, 1, 0, 1, 0, 0], device='cuda:0')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**The next batch will have different text column size.**\n",
        "\n",
        "The column size is determined by the max length of reviews in a batch. Each batch has a different text column size."
      ],
      "metadata": {
        "id": "SbKYBRznQgi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_batch, label_batch = next(iter(train_loader))\n",
        "print(f'Text matrix size: {text_batch.size()}')\n",
        "print(f'Target vector size: {label_batch.size()}')\n",
        "\n",
        "text_batch, label_batch = next(iter(train_dataloader))\n",
        "print(f'Text matrix size: {text_batch.size()}')\n",
        "print(f'Target vector size: {label_batch.size()}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFpzgfY5Qfnv",
        "outputId": "cace563b-c1f0-405c-c6ce-b8109dd541bc"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Text matrix size: torch.Size([1289, 128])\n",
            "Target vector size: torch.Size([128])\n",
            "Text matrix size: torch.Size([1153, 128])\n",
            "Target vector size: torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To group the texts with similar length together, like introduced in the legacy `BucketIterator` class, first of all, we randomly create multiple \"pools\", and each of them has a size of `batch_size * 100`. Then, we sort the samples within the individual pool by length. This idea can be implemented succintly through `batch_sampler` argument of PyTorch `Dataloader`. `batch_sampler` accepts 'Sampler' or Iterable object that yields indices of next batch. In the code below, we implemented a generator that yields batch of indices for which the corresponding batch of data is of similar length. "
      ],
      "metadata": {
        "id": "PPVGxmEsCR6h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_list = list(train_dp)\n",
        "\n",
        "def batch_sampler():\n",
        "    indices = [(i, len(tokenizer(s[0]))) for i, s in enumerate(train_list)]\n",
        "    random.shuffle(indices)\n",
        "    pooled_indices = []\n",
        "    # create pool of indices with similar lengths \n",
        "    for i in range(0, len(indices), BATCH_SIZE * 100): \n",
        "       pooled_indices.extend(sorted(indices[i:i + BATCH_SIZE * 100], key=lambda x: x[0]))\n",
        "\n",
        "    pooled_indices = [x[1] for x in pooled_indices]\n",
        "\n",
        "    # yield indices for current batch\n",
        "    for i in range(0, len(pooled_indices), BATCH_SIZE):\n",
        "        yield pooled_indices[i:i + BATCH_SIZE]\n",
        "\n",
        "train_loader1 = DataLoader(train_list, batch_sampler=batch_sampler(),\n",
        "                           collate_fn=collate_batch)\n",
        "\n",
        "text_batch, label_batch = next(iter(train_loader1))\n",
        "print(text_batch.size())\n",
        "print(label_batch.size())"
      ],
      "metadata": {
        "id": "eH4w2xp3CcA_",
        "outputId": "6c51e1ab-07ac-4ab4-a9f7-5df684f0c10d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1197, 128])\n",
            "torch.Size([128])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(vec_vocab_itos(text_batch))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BopSzNUXRIOO",
        "outputId": "e3519492-95e4-45af-80bf-95ea06bfba13"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['this' 'the' 'still' ... 'i' 'to' 'it']\n",
            " ['was' 'animation' 'crazy' ... 'almost' 'be' \"'\"]\n",
            " ['an' 'quality' 'is' ... 'laughed' 'fair' 's']\n",
            " ...\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']\n",
            " ['<PAD>' '<PAD>' '<PAD>' ... '<PAD>' '<PAD>' '<PAD>']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(label_batch)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yDM8DBXkRJjy",
        "outputId": "6740eb10-66ee-4f01-ccc5-ef528282aa3c"
      },
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1,\n",
            "        0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1,\n",
            "        1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1,\n",
            "        0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0,\n",
            "        1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0,\n",
            "        0, 0, 0, 1, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_grdW3pxCzz"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {
        "id": "nQIUm5EjxFNa"
      },
      "outputs": [],
      "source": [
        "class RNN(torch.nn.Module):\n",
        "    \n",
        "    def __init__(self, input_dim, embedding_dim, hidden_dim, output_dim):\n",
        "        super().__init__()\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(input_dim, embedding_dim)\n",
        "        #self.rnn = torch.nn.RNN(embedding_dim,\n",
        "        #                        hidden_dim,\n",
        "        #                        nonlinearity='relu')\n",
        "        self.rnn = torch.nn.LSTM(embedding_dim,\n",
        "                                 hidden_dim)        \n",
        "        \n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "\n",
        "    def forward(self, text):\n",
        "        # text dim: [sentence length, batch size]\n",
        "        print(f\"In forward(): {text.size()}\")\n",
        "        \n",
        "        embedded = self.embedding(text)\n",
        "        # embedded dim: [sentence length, batch size, embedding dim]\n",
        "        \n",
        "        output, (hidden, cell) = self.rnn(embedded)\n",
        "        # output dim: [sentence length, batch size, hidden dim]\n",
        "        # hidden dim: [1, batch size, hidden dim]\n",
        "\n",
        "        hidden.squeeze_(0)\n",
        "        # hidden dim: [batch size, hidden dim]\n",
        "        \n",
        "        output = self.fc(hidden)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {
        "id": "Ik3NF3faxFmZ"
      },
      "outputs": [],
      "source": [
        "torch.manual_seed(RANDOM_SEED)\n",
        "model = RNN(input_dim=len(vocab),\n",
        "            embedding_dim=EMBEDDING_DIM,\n",
        "            hidden_dim=HIDDEN_DIM,\n",
        "            output_dim=NUM_CLASSES # could use 1 for binary classification\n",
        ")\n",
        "\n",
        "model = model.to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.005)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lv9Ny9di6VcI"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "T5t1Afn4xO11"
      },
      "outputs": [],
      "source": [
        "def compute_accuracy(model, data_loader, device):\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        correct_pred, num_examples = 0, 0\n",
        "\n",
        "        for i, (features, targets) in enumerate(data_loader):\n",
        "\n",
        "            features = features.to(device)\n",
        "            targets = targets.float().to(device)\n",
        "\n",
        "            logits = model(features)\n",
        "            _, predicted_labels = torch.max(logits, 1)\n",
        "\n",
        "            num_examples += targets.size(0)\n",
        "            correct_pred += (predicted_labels == targets).sum()\n",
        "    return correct_pred.float()/num_examples * 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EABZM8Vo0ilB",
        "outputId": "d580134f-d91b-41b2-8434-ad14398b4919"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch: 001/015 | Batch 001/313 | Loss: 0.6959\n",
            "Epoch: 001/015 | Batch 051/313 | Loss: 0.6945\n",
            "Epoch: 001/015 | Batch 101/313 | Loss: 0.6918\n",
            "Epoch: 001/015 | Batch 151/313 | Loss: 0.6925\n",
            "Epoch: 001/015 | Batch 201/313 | Loss: 0.6918\n",
            "Epoch: 001/015 | Batch 251/313 | Loss: 0.6937\n",
            "Epoch: 001/015 | Batch 301/313 | Loss: 0.6928\n",
            "training accuracy: 50.00%\n",
            "valid accuracy: 49.74%\n",
            "Time elapsed: 1.27 min\n",
            "Epoch: 002/015 | Batch 001/313 | Loss: 0.6945\n",
            "Epoch: 002/015 | Batch 051/313 | Loss: 0.6908\n",
            "Epoch: 002/015 | Batch 101/313 | Loss: 0.6896\n",
            "Epoch: 002/015 | Batch 151/313 | Loss: 0.6974\n",
            "Epoch: 002/015 | Batch 201/313 | Loss: 0.6993\n",
            "Epoch: 002/015 | Batch 251/313 | Loss: 0.6866\n",
            "Epoch: 002/015 | Batch 301/313 | Loss: 0.6887\n",
            "training accuracy: 50.15%\n",
            "valid accuracy: 50.28%\n",
            "Time elapsed: 2.62 min\n",
            "Epoch: 003/015 | Batch 001/313 | Loss: 0.6924\n",
            "Epoch: 003/015 | Batch 051/313 | Loss: 0.6874\n",
            "Epoch: 003/015 | Batch 101/313 | Loss: 0.6884\n",
            "Epoch: 003/015 | Batch 151/313 | Loss: 0.6890\n",
            "Epoch: 003/015 | Batch 201/313 | Loss: 0.6935\n",
            "Epoch: 003/015 | Batch 251/313 | Loss: 0.6972\n",
            "Epoch: 003/015 | Batch 301/313 | Loss: 0.6907\n",
            "training accuracy: 50.02%\n",
            "valid accuracy: 49.76%\n",
            "Time elapsed: 3.87 min\n",
            "Epoch: 004/015 | Batch 001/313 | Loss: 0.6862\n",
            "Epoch: 004/015 | Batch 051/313 | Loss: 0.6975\n",
            "Epoch: 004/015 | Batch 101/313 | Loss: 0.6897\n",
            "Epoch: 004/015 | Batch 151/313 | Loss: 0.6891\n",
            "Epoch: 004/015 | Batch 201/313 | Loss: 0.6505\n",
            "Epoch: 004/015 | Batch 251/313 | Loss: 0.6192\n",
            "Epoch: 004/015 | Batch 301/313 | Loss: 0.5849\n",
            "training accuracy: 69.46%\n",
            "valid accuracy: 68.58%\n",
            "Time elapsed: 5.15 min\n",
            "Epoch: 005/015 | Batch 001/313 | Loss: 0.5660\n",
            "Epoch: 005/015 | Batch 051/313 | Loss: 0.4733\n",
            "Epoch: 005/015 | Batch 101/313 | Loss: 0.5240\n",
            "Epoch: 005/015 | Batch 151/313 | Loss: 0.5095\n",
            "Epoch: 005/015 | Batch 201/313 | Loss: 0.4521\n",
            "Epoch: 005/015 | Batch 251/313 | Loss: 0.4433\n",
            "Epoch: 005/015 | Batch 301/313 | Loss: 0.4625\n",
            "training accuracy: 85.94%\n",
            "valid accuracy: 83.38%\n",
            "Time elapsed: 6.48 min\n",
            "Epoch: 006/015 | Batch 001/313 | Loss: 0.4925\n",
            "Epoch: 006/015 | Batch 051/313 | Loss: 0.4102\n",
            "Epoch: 006/015 | Batch 101/313 | Loss: 0.4180\n",
            "Epoch: 006/015 | Batch 151/313 | Loss: 0.3926\n",
            "Epoch: 006/015 | Batch 201/313 | Loss: 0.3290\n",
            "Epoch: 006/015 | Batch 251/313 | Loss: 0.3761\n",
            "Epoch: 006/015 | Batch 301/313 | Loss: 0.3677\n",
            "training accuracy: 89.70%\n",
            "valid accuracy: 85.70%\n",
            "Time elapsed: 7.77 min\n",
            "Epoch: 007/015 | Batch 001/313 | Loss: 0.3222\n",
            "Epoch: 007/015 | Batch 051/313 | Loss: 0.2409\n",
            "Epoch: 007/015 | Batch 101/313 | Loss: 0.3302\n",
            "Epoch: 007/015 | Batch 151/313 | Loss: 0.2427\n",
            "Epoch: 007/015 | Batch 201/313 | Loss: 0.2787\n",
            "Epoch: 007/015 | Batch 251/313 | Loss: 0.3135\n",
            "Epoch: 007/015 | Batch 301/313 | Loss: 0.2874\n",
            "training accuracy: 91.78%\n",
            "valid accuracy: 86.54%\n",
            "Time elapsed: 9.06 min\n",
            "Epoch: 008/015 | Batch 001/313 | Loss: 0.2221\n",
            "Epoch: 008/015 | Batch 051/313 | Loss: 0.2113\n",
            "Epoch: 008/015 | Batch 101/313 | Loss: 0.3017\n",
            "Epoch: 008/015 | Batch 151/313 | Loss: 0.1873\n",
            "Epoch: 008/015 | Batch 201/313 | Loss: 0.2137\n",
            "Epoch: 008/015 | Batch 251/313 | Loss: 0.1929\n",
            "Epoch: 008/015 | Batch 301/313 | Loss: 0.1823\n",
            "training accuracy: 93.10%\n",
            "valid accuracy: 85.96%\n",
            "Time elapsed: 10.37 min\n",
            "Epoch: 009/015 | Batch 001/313 | Loss: 0.1607\n",
            "Epoch: 009/015 | Batch 051/313 | Loss: 0.1988\n",
            "Epoch: 009/015 | Batch 101/313 | Loss: 0.1650\n",
            "Epoch: 009/015 | Batch 151/313 | Loss: 0.1925\n",
            "Epoch: 009/015 | Batch 201/313 | Loss: 0.3021\n",
            "Epoch: 009/015 | Batch 251/313 | Loss: 0.2654\n",
            "Epoch: 009/015 | Batch 301/313 | Loss: 0.2417\n",
            "training accuracy: 94.38%\n",
            "valid accuracy: 86.68%\n",
            "Time elapsed: 11.65 min\n",
            "Epoch: 010/015 | Batch 001/313 | Loss: 0.2418\n",
            "Epoch: 010/015 | Batch 051/313 | Loss: 0.2344\n",
            "Epoch: 010/015 | Batch 101/313 | Loss: 0.2761\n",
            "Epoch: 010/015 | Batch 151/313 | Loss: 0.1675\n",
            "Epoch: 010/015 | Batch 201/313 | Loss: 0.2087\n",
            "Epoch: 010/015 | Batch 251/313 | Loss: 0.2119\n",
            "Epoch: 010/015 | Batch 301/313 | Loss: 0.1621\n",
            "training accuracy: 95.22%\n",
            "valid accuracy: 87.28%\n",
            "Time elapsed: 12.94 min\n",
            "Epoch: 011/015 | Batch 001/313 | Loss: 0.1719\n",
            "Epoch: 011/015 | Batch 051/313 | Loss: 0.1526\n",
            "Epoch: 011/015 | Batch 101/313 | Loss: 0.1601\n",
            "Epoch: 011/015 | Batch 151/313 | Loss: 0.0937\n",
            "Epoch: 011/015 | Batch 201/313 | Loss: 0.2102\n",
            "Epoch: 011/015 | Batch 251/313 | Loss: 0.1337\n",
            "Epoch: 011/015 | Batch 301/313 | Loss: 0.1521\n",
            "training accuracy: 95.99%\n",
            "valid accuracy: 87.02%\n",
            "Time elapsed: 14.24 min\n",
            "Epoch: 012/015 | Batch 001/313 | Loss: 0.1256\n",
            "Epoch: 012/015 | Batch 051/313 | Loss: 0.1616\n",
            "Epoch: 012/015 | Batch 101/313 | Loss: 0.0626\n",
            "Epoch: 012/015 | Batch 151/313 | Loss: 0.0975\n",
            "Epoch: 012/015 | Batch 201/313 | Loss: 0.1672\n",
            "Epoch: 012/015 | Batch 251/313 | Loss: 0.1803\n",
            "Epoch: 012/015 | Batch 301/313 | Loss: 0.1603\n",
            "training accuracy: 96.66%\n",
            "valid accuracy: 87.54%\n",
            "Time elapsed: 15.51 min\n",
            "Epoch: 013/015 | Batch 001/313 | Loss: 0.0913\n",
            "Epoch: 013/015 | Batch 051/313 | Loss: 0.0575\n",
            "Epoch: 013/015 | Batch 101/313 | Loss: 0.1465\n",
            "Epoch: 013/015 | Batch 151/313 | Loss: 0.1350\n",
            "Epoch: 013/015 | Batch 201/313 | Loss: 0.1079\n",
            "Epoch: 013/015 | Batch 251/313 | Loss: 0.1371\n",
            "Epoch: 013/015 | Batch 301/313 | Loss: 0.2276\n",
            "training accuracy: 96.79%\n",
            "valid accuracy: 86.74%\n",
            "Time elapsed: 16.79 min\n",
            "Epoch: 014/015 | Batch 001/313 | Loss: 0.0850\n",
            "Epoch: 014/015 | Batch 051/313 | Loss: 0.1767\n",
            "Epoch: 014/015 | Batch 101/313 | Loss: 0.1203\n",
            "Epoch: 014/015 | Batch 151/313 | Loss: 0.0793\n",
            "Epoch: 014/015 | Batch 201/313 | Loss: 0.1247\n",
            "Epoch: 014/015 | Batch 251/313 | Loss: 0.1819\n",
            "Epoch: 014/015 | Batch 301/313 | Loss: 0.0966\n",
            "training accuracy: 97.47%\n",
            "valid accuracy: 87.28%\n",
            "Time elapsed: 18.10 min\n",
            "Epoch: 015/015 | Batch 001/313 | Loss: 0.0702\n",
            "Epoch: 015/015 | Batch 051/313 | Loss: 0.1150\n",
            "Epoch: 015/015 | Batch 101/313 | Loss: 0.1119\n",
            "Epoch: 015/015 | Batch 151/313 | Loss: 0.0892\n",
            "Epoch: 015/015 | Batch 201/313 | Loss: 0.1007\n",
            "Epoch: 015/015 | Batch 251/313 | Loss: 0.1292\n",
            "Epoch: 015/015 | Batch 301/313 | Loss: 0.1217\n",
            "training accuracy: 97.72%\n",
            "valid accuracy: 87.74%\n",
            "Time elapsed: 19.38 min\n",
            "Total Training Time: 19.38 min\n",
            "Test accuracy: 87.50%\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "\n",
        "for epoch in range(NUM_EPOCHS):\n",
        "    model.train()\n",
        "    for batch_idx, (text_batch, label_batch) in enumerate(train_loader):\n",
        "\n",
        "        ### FORWARD AND BACK PROP\n",
        "        logits = model(text_batch)\n",
        "        loss = F.cross_entropy(logits, label_batch)\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        loss.backward()\n",
        "        \n",
        "        ### UPDATE MODEL PARAMETERS\n",
        "        optimizer.step()\n",
        "        \n",
        "        ### LOGGING\n",
        "        if not batch_idx % 50:\n",
        "            print (f'Epoch: {epoch+1:03d}/{NUM_EPOCHS:03d} | '\n",
        "                   f'Batch {batch_idx+1:03d}/{len(train_loader):03d} | '\n",
        "                   f'Loss: {loss:.4f}')\n",
        "\n",
        "    with torch.set_grad_enabled(False):\n",
        "        print(f'training accuracy: '\n",
        "              f'{compute_accuracy(model, train_loader, DEVICE):.2f}%'\n",
        "              f'\\nvalid accuracy: '\n",
        "              f'{compute_accuracy(model, valid_loader, DEVICE):.2f}%')\n",
        "        \n",
        "    print(f'Time elapsed: {(time.time() - start_time)/60:.2f} min')\n",
        "    \n",
        "print(f'Total Training Time: {(time.time() - start_time)/60:.2f} min')\n",
        "print(f'Test accuracy: {compute_accuracy(model, test_loader, DEVICE):.2f}%')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_sentiment(model, sentence):\n",
        "\n",
        "    model.eval()\n",
        "    tokenized = tokenizer(sentence)\n",
        "    indexed = [vocab[t] for t in tokenized]\n",
        "    length = [len(indexed)]\n",
        "    tensor = torch.LongTensor(indexed).to(DEVICE)\n",
        "    tensor = tensor.unsqueeze(1)\n",
        "    length_tensor = torch.LongTensor(length)\n",
        "    prediction = F.softmax(model(tensor), dim=1)\n",
        "    return prediction.to(\"cpu\").squeeze(dim=0).detach().numpy()\n",
        "\n",
        "print('Probability positive:')\n",
        "predict_sentiment(model, \"This is such an awesome movie, I really love it!\")[1]\n"
      ],
      "metadata": {
        "id": "V3Z8HBMZkWG2",
        "outputId": "9da11826-442f-404c-a60d-303bca653138",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability positive:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.99810505"
            ]
          },
          "metadata": {},
          "execution_count": 187
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Probability negative:')\n",
        "predict_sentiment(model, \"I really hate this movie. It is really bad and sucks!\")[0]"
      ],
      "metadata": {
        "id": "jS-4s-9bk_oo",
        "outputId": "ff27c703-fea3-4243-cb30-3a7b024e4910",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 188,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability negative:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.93780214"
            ]
          },
          "metadata": {},
          "execution_count": 188
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 189,
      "metadata": {
        "id": "7lRusB3dF80X",
        "outputId": "23f72fc7-b5e8-4ad3-c957-cad15e8a1763",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torchtext: 0.14.0\n",
            "torch    : 1.13.0+cu116\n",
            "spacy    : 3.4.3\n",
            "colab_env: 0.2.0\n",
            "numpy    : 1.21.6\n",
            "sys      : 3.8.16 (default, Dec  7 2022, 01:12:13) \n",
            "[GCC 7.5.0]\n",
            "google   : 2.0.3\n",
            "pandas   : 1.3.5\n",
            "\n"
          ]
        }
      ],
      "source": [
        "%watermark -iv"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "rnn_lstm_packed_imdb.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}